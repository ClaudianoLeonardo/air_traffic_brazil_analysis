{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qg504fdEG-8I",
        "outputId": "4cf22c0b-43d1-472f-f305-a59024320101"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "path = '/content/drive/MyDrive/dataset-flights-brazil-main/dataset-flights-brazil-main/data/extract'\n",
        "\n",
        "# Flights (ANAC)\n",
        "url = 'https://www.gov.br/anac/pt-br/assuntos/dados-e-estatisticas/dados-estatisticos'\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "# Get all links\n",
        "tags_a = soup.find_all('a', {\n",
        "    'target': '_self',\n",
        "    'class': 'internal-link',\n",
        "})\n",
        "links = [tag_a['href'] for tag_a in tags_a if tag_a['href'].endswith('.csv')]\n",
        "\n",
        "# Download all files\n",
        "for link in tqdm(links):\n",
        "    filename = path + link.split('/')[-1]\n",
        "    if os.path.exists(filename):\n",
        "        continue\n",
        "\n",
        "    file_response = requests.get(link)\n",
        "    open(filename, 'wb').write(file_response.content)\n",
        "\n",
        "# Public aerodromes (ANAC)\n",
        "url = 'https://sistemas.anac.gov.br/dadosabertos/Aerodromos/Lista%20de%20aer%C3%B3dromos%20p%C3%BAblicos/AerodromosPublicos.csv'\n",
        "file_response = requests.get(url)\n",
        "open(path + 'public_aerodromes.csv', 'wb').write(file_response.content)\n",
        "\n",
        "# Airport Codes (DataHub.io)\n",
        "url = 'https://datahub.io/core/airport-codes/r/airport-codes.csv'\n",
        "file_response = requests.get(url)\n",
        "open(path + 'airport_codes.csv', 'wb').write(file_response.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IMioYnFH2vz",
        "outputId": "32ea1dad-e481-4a8f-9c8e-781060b15b63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 23/23 [09:14<00:00, 24.13s/it]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6232459"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install geocoder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFbewovWLevz",
        "outputId": "1637a406-a84c-4fb1-b0e0-f626fc51455d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting geocoder\n",
            "  Downloading geocoder-1.38.1-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 2.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from geocoder) (0.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from geocoder) (2.23.0)\n",
            "Collecting ratelim\n",
            "  Downloading ratelim-0.1.6-py2.py3-none-any.whl (4.0 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from geocoder) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from geocoder) (1.15.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ratelim->geocoder) (4.4.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->geocoder) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->geocoder) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->geocoder) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->geocoder) (2022.9.24)\n",
            "Installing collected packages: ratelim, geocoder\n",
            "Successfully installed geocoder-1.38.1 ratelim-0.1.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "\n",
        "files = glob.glob('/content/drive/MyDrive/dataset-flights-brazil-main/dataset-flights-brazil-main/data/extractresumo_anual_*.csv')\n",
        "\n",
        "# Combine all files in the list\n",
        "combined_csv = pd.concat([pd.read_csv(file, sep=';', encoding='ISO-8859-1') for file in files])\n",
        "\n",
        "# Rename columns\n",
        "columns_map = {\n",
        "    'EMPRESA (SIGLA)': 'company_abbreviation',\n",
        "    'EMPRESA (NOME)': 'company_name',\n",
        "    'EMPRESA (NACIONALIDADE)': 'company_nationality',\n",
        "    'ANO': 'year',\n",
        "    'MÊS': 'month',\n",
        "    'AEROPORTO DE ORIGEM (SIGLA)': 'origin_airport_abbreviation',\n",
        "    'AEROPORTO DE ORIGEM (NOME)': 'origin_airport_name',\n",
        "    'AEROPORTO DE ORIGEM (UF)': 'origin_airport_state',\n",
        "    'AEROPORTO DE ORIGEM (REGIÃO)': 'origin_airport_region',\n",
        "    'AEROPORTO DE ORIGEM (PAÍS)': 'origin_airport_country',\n",
        "    'AEROPORTO DE ORIGEM (CONTINENTE)': 'origin_airport_continent',\n",
        "    'AEROPORTO DE DESTINO (SIGLA)': 'destination_airport_abbreviation',\n",
        "    'AEROPORTO DE DESTINO (NOME)': 'destination_airport_name',\n",
        "    'AEROPORTO DE DESTINO (UF)': 'destination_airport_state',\n",
        "    'AEROPORTO DE DESTINO (REGIÃO)': 'destination_airport_region',\n",
        "    'AEROPORTO DE DESTINO (PAÍS)': 'destination_airport_country',\n",
        "    'AEROPORTO DE DESTINO (CONTINENTE)': 'destination_airport_continent',\n",
        "    'NATUREZA': 'nature',\n",
        "    'GRUPO DE VOO': 'flight_group',\n",
        "    'PASSAGEIROS PAGOS': 'paid_passenger',\n",
        "    'PASSAGEIROS GRÁTIS': 'free_passenger',\n",
        "    'CARGA PAGA (KG)': 'charge_paid_kg',\n",
        "    'CARGA GRÁTIS (KG)': 'charge_free_kg',\n",
        "    'CORREIO (KG)': 'mail_kg',\n",
        "    'ASK': 'ask',\n",
        "    'RPK': 'rpk',\n",
        "    'ATK': 'atk',\n",
        "    'RTK': 'rtk',\n",
        "    'COMBUSTÍVEL (LITROS)': 'fuel_l',\n",
        "    'DISTÂNCIA VOADA (KM)': 'distance_flown_km',\n",
        "    'DECOLAGENS': 'takeoffs',\n",
        "    'CARGA PAGA KM': 'charge_paid_km',\n",
        "    'CARGA GRATIS KM': 'charge_free_km',\n",
        "    'CORREIO KM': 'mail_km',\n",
        "    'ASSENTOS': 'seats',\n",
        "    'PAYLOAD': 'payload',\n",
        "    'HORAS VOADAS': 'fly_hours',\n",
        "    'BAGAGEM (KG)': 'baggage_kg',\n",
        "}\n",
        "combined_csv = combined_csv.rename(columns=columns_map)\n",
        "\n",
        "# Export to csv\n",
        "combined_csv.to_csv('/content/drive/MyDrive/dataset-flights-brazil-main/dataset-flights-brazil-main/data/anac.csv', index=False, encoding='utf-8')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoY8ZRIqL2VR",
        "outputId": "2cd64a26-1824-4364-92b8-35077b6c5739"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: DtypeWarning: Columns (24,25,29) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  import sys\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import geocoder\n",
        "import pandas as pd\n",
        "\n",
        "path = '/content/drive/MyDrive/dataset-flights-brazil-main/dataset-flights-brazil-main/data/extract'\n",
        "\n",
        "# ANAC dataset\n",
        "anac_columns = [\n",
        "    'origin_airport_abbreviation',\n",
        "    'origin_airport_name',\n",
        "    'origin_airport_state',\n",
        "    'origin_airport_region',\n",
        "    'origin_airport_country',\n",
        "    'origin_airport_continent',\n",
        "    'destination_airport_abbreviation',\n",
        "    'destination_airport_name',\n",
        "    'destination_airport_state',\n",
        "    'destination_airport_region',\n",
        "    'destination_airport_country',\n",
        "    'destination_airport_continent',\n",
        "]\n",
        "df_anac = pd.read_csv('/content/drive/MyDrive/dataset-flights-brazil-main/dataset-flights-brazil-main/data/anac.csv', usecols=anac_columns)\n",
        "\n",
        "# Get airports from ANAC\n",
        "same_columns = {\n",
        "    'origin_airport_abbreviation': 'code',\n",
        "    'origin_airport_name': 'name',\n",
        "    'origin_airport_state': 'state',\n",
        "    'origin_airport_region': 'region',\n",
        "    'origin_airport_country': 'country',\n",
        "    'origin_airport_continent': 'continent',\n",
        "    'destination_airport_abbreviation': 'code',\n",
        "    'destination_airport_name': 'name',\n",
        "    'destination_airport_state': 'state',\n",
        "    'destination_airport_region': 'region',\n",
        "    'destination_airport_country': 'country',\n",
        "    'destination_airport_continent': 'continent',\n",
        "}\n",
        "origin_columns = [\n",
        "    'origin_airport_abbreviation',\n",
        "    'origin_airport_name',\n",
        "    'origin_airport_state',\n",
        "    'origin_airport_region',\n",
        "    'origin_airport_country',\n",
        "    'origin_airport_continent',\n",
        "]\n",
        "destination_columns = [\n",
        "    'destination_airport_abbreviation',\n",
        "    'destination_airport_name',\n",
        "    'destination_airport_state',\n",
        "    'destination_airport_region',\n",
        "    'destination_airport_country',\n",
        "    'destination_airport_continent',\n",
        "]\n",
        "\n",
        "df_origins = df_anac[origin_columns]\n",
        "df_origins = df_origins.rename(columns=same_columns)\n",
        "\n",
        "df_destinations = df_anac[destination_columns]\n",
        "df_destinations = df_destinations.rename(columns=same_columns)\n",
        "\n",
        "df_airports = pd.concat([df_origins, df_destinations])\n",
        "df_airports = df_airports.drop_duplicates()\n",
        "\n",
        "# Airfields dataset\n",
        "airfields_columns = [\n",
        "    'Código OACI',\n",
        "    'LATGEOPOINT',\n",
        "    'LONGEOPOINT',\n",
        "]\n",
        "df_airfields = pd.read_csv(path + 'public_aerodromes.csv',\n",
        "                           sep=';',\n",
        "                           usecols=airfields_columns,\n",
        "                           skiprows=1,\n",
        "                           encoding='ISO-8859-1')\n",
        "\n",
        "# Rename columns\n",
        "columns_map = {\n",
        "    'CÓDIGO OACI': 'code',\n",
        "    'LATGEOPOINT': 'lat_geo_point',\n",
        "    'LONGEOPOINT': 'lon_geo_point',\n",
        "}\n",
        "df_airfields = df_airfields.rename(columns=columns_map)\n",
        "\n",
        "# Others airports\n",
        "others_airports_columns = [\n",
        "    'ident',\n",
        "    'coordinates',\n",
        "]\n",
        "df_others_airports = pd.read_csv(path + 'airport_codes.csv', usecols=others_airports_columns)\n",
        "\n",
        "# Rename columns\n",
        "columns_map = {\n",
        "    'ident': 'code',\n",
        "}\n",
        "df_others_airports = df_others_airports.rename(columns=columns_map)\n",
        "df_others_airports[['lon_geo_point', 'lat_geo_point']] = df_others_airports.coordinates.str.split(', ', expand=True, )\n",
        "df_others_airports = df_others_airports.drop(columns=['coordinates'])\n",
        "\n",
        "# Coordinates dataframe\n",
        "df_coordinates = pd.concat([df_airfields, df_others_airports])\n",
        "\n",
        "# Merge dataframe\n",
        "df_merge = pd.merge(\n",
        "    df_airports,\n",
        "    df_coordinates,\n",
        "    how='left',\n",
        "    left_on='code',\n",
        "    right_on='code')\n",
        "df_merge = df_merge.dropna(how='all')\n",
        "df_merge = df_merge.drop_duplicates('code')\n",
        "\n",
        "# Find the others geolocations\n",
        "columns = [\n",
        "    'name',\n",
        "    'state',\n",
        "    'region',\n",
        "    'country',\n",
        "    'continent',\n",
        "]\n",
        "airports_to_find = []\n",
        "for index, row in df_merge[df_merge.lat_geo_point.isnull()].iterrows():\n",
        "    label = ''\n",
        "\n",
        "    for column in columns:\n",
        "        if type(row[column]) == str and row[column]:\n",
        "            label += row[column] + ', '\n",
        "\n",
        "    if not label:\n",
        "        continue\n",
        "\n",
        "    geo_result = geocoder.arcgis(label[:-2])\n",
        "    df_merge.loc[df_merge.code == row['code'], 'lat_geo_point'] = geo_result.latlng[0]\n",
        "    df_merge.loc[df_merge.code == row['code'], 'lon_geo_point'] = geo_result.latlng[1]\n",
        "\n",
        "# Save result\n",
        "df_merge.to_csv('/content/drive/MyDrive/dataset-flights-brazil-main/dataset-flights-brazil-main/data/airports.csv', index=False, encoding='utf-8')"
      ],
      "metadata": {
        "id": "nQFitM_cIy9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k09WwfV2Bjeg",
        "outputId": "1087d7f2-02e3-44e3-af58-626ed46f817a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (24,25,29) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ],
      "source": [
        "import networkx as nx\n",
        "import pandas as pd\n",
        "\n",
        "df_airports = pd.read_csv('/content/drive/MyDrive/dataset-flights-brazil-main/dataset-flights-brazil-main/data/airports.csv')\n",
        "df_flights = pd.read_csv('/content/drive/MyDrive/dataset-flights-brazil-main/dataset-flights-brazil-main/data/anac.csv')\n",
        "\n",
        "# Create graph\n",
        "G = nx.Graph()\n",
        "\n",
        "# Add nodes\n",
        "for index, row in df_airports.iterrows():\n",
        "    G.add_node(row['code'],\n",
        "               name=row['name'],\n",
        "               country=row['country'],\n",
        "               latitude=row['lat_geo_point'],\n",
        "               longitude=row['lon_geo_point'],\n",
        "               region=row['region']\n",
        "               )\n",
        "\n",
        "# Add edges\n",
        "df_edges = df_flights[[\n",
        "    'origin_airport_abbreviation',\n",
        "    'destination_airport_abbreviation',\n",
        "]].dropna()\n",
        "df_edges = df_edges.groupby(df_edges.columns.tolist(), as_index=False).size()\n",
        "for index, row in df_edges.iterrows():\n",
        "    if row['origin_airport_abbreviation'] == row['destination_airport_abbreviation']:\n",
        "        continue\n",
        "    G.add_edge(row['origin_airport_abbreviation'], row['destination_airport_abbreviation'], flight_count=row['size'])\n",
        "\n",
        "# Export to graphml\n",
        "nx.write_graphml(G, '/content/drive/MyDrive/dataset-flights-brazil-main/dataset-flights-brazil-main/data/air_traffic.graphml')\n"
      ]
    }
  ]
}